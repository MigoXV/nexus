from typing import Iterable, Optional, List
import asyncio
import json
import logging
from dataclasses import dataclass
from typing import TYPE_CHECKING

from openai.types import realtime
from openai.types.chat import ChatCompletionChunk

from nexus.inferencers.asr.inferencer import TranscriptionResult

from .utils import get_event_id, get_item_id, get_response_id, get_conversation_id
from .contexts import TextResponseContext, FunctionCallResponseContext, McpCallResponseContext
from .build_events import (
    build_response_text_delta,
    build_response_text_done,
)

if TYPE_CHECKING:
    from nexus.sessions import RealtimeSession

logger = logging.getLogger(__name__)


def get_usage_tokens(transcript: str):
    """è®¡ç®—è½¬å½•æ–‡æœ¬çš„ä½¿ç”¨ token æ•°"""
    # ç®€å•æŒ‰ç©ºæ ¼åˆ†è¯è®¡æ•°ï¼Œå®é™…å¯æ ¹æ®å…·ä½“æ¨¡å‹çš„ tokenizer å®ç°æ›´ç²¾ç¡®çš„è®¡æ•°
    tokens = len(transcript.strip().split())
    usage = realtime.conversation_item_input_audio_transcription_completed_event.UsageTranscriptTextUsageTokens(
        total_tokens=tokens,
        output_tokens=0,
        input_tokens=tokens,
        type="tokens",
    )
    return usage


async def send_transcribe_response(
    session: "RealtimeSession",
    transcription_result: TranscriptionResult,
):
    item_id = get_item_id()
    is_final = transcription_result.is_final
    if not is_final:
        logger.warning(
            f"send_transcribe_response called with non-final result, item_id={item_id}"
        )
        return
    transcript = transcription_result.transcript
    _, start_time, end_time = transcription_result.words[0]
    vad_start_event = realtime.InputAudioBufferSpeechStartedEvent(
        audio_start_ms=int(start_time * 1000),
        type="input_audio_buffer.speech_started",
        event_id=get_event_id(),
        item_id=item_id,
    )
    await session.send_event(vad_start_event)
    vad_stop_event = realtime.InputAudioBufferSpeechStoppedEvent(
        audio_end_ms=int(end_time * 1000),
        type="input_audio_buffer.speech_stopped",
        event_id=get_event_id(),
        item_id=item_id,
    )
    await session.send_event(vad_stop_event)
    committed_event = realtime.InputAudioBufferCommittedEvent(
        event_id=get_event_id(),
        item_id=item_id,
        type="input_audio_buffer.committed",
    )
    await session.send_event(committed_event)
    delta_event = realtime.ConversationItemInputAudioTranscriptionDeltaEvent(
        event_id=get_event_id(),
        item_id=item_id,
        type="conversation.item.input_audio_transcription.delta",
        content_index=0,
        delta=transcript,
    )
    await session.send_event(delta_event)
    completed_event = realtime.ConversationItemInputAudioTranscriptionCompletedEvent(
        content_index=0,
        event_id=get_event_id(),
        item_id=item_id,
        transcript=transcript,
        type="conversation.item.input_audio_transcription.completed",
        usage=get_usage_tokens(transcript),
    )
    await session.send_event(completed_event)

    item = realtime.RealtimeConversationItemUserMessage(
        content=[
            realtime.realtime_conversation_item_user_message.Content(type="input_audio")
        ],
        role="user",
        type="message",
        id=item_id,
        object=None,
        status="completed",
    )
    conversation_add_event = realtime.ConversationItemAdded(
        event_id=get_event_id(), item=item, type="conversation.item.added"
    )
    await session.send_event(conversation_add_event)
    conversation_done_event = realtime.ConversationItemDone(
        event_id=get_event_id(), item=item, type="conversation.item.done"
    )
    await session.send_event(conversation_done_event)

    logger.info(
        f"Sent transcription response: item_id={item_id}, is_final={is_final}, transcript='{transcript}'"
    )


@dataclass
class ToolCallInfo:
    """å·¥å…·è°ƒç”¨ä¿¡æ¯"""
    call_id: str
    name: str
    arguments: str
    is_mcp: bool = False  # æ˜¯å¦ä¸º MCP å·¥å…·è°ƒç”¨
    server_label: Optional[str] = None  # MCP æœåŠ¡å™¨æ ‡ç­¾
    mcp_ctx: Optional["McpCallResponseContext"] = None  # MCP ä¸Šä¸‹æ–‡ï¼ˆç”¨äºåç»­äº‹ä»¶å‘é€ï¼‰


@dataclass 
class ChatStreamResult:
    """èŠå¤©æµå¼å“åº”ç»“æœ"""
    content: str = ""
    tool_call: Optional[ToolCallInfo] = None
    was_cancelled: bool = False  # æ˜¯å¦è¢«æ‰“æ–­
    
    @property
    def has_tool_call(self) -> bool:
        return self.tool_call is not None
    
    @property
    def has_mcp_call(self) -> bool:
        return self.tool_call is not None and self.tool_call.is_mcp


async def process_chat_stream(
    session: "RealtimeSession",
    chat_stream: Iterable[ChatCompletionChunk],
) -> ChatStreamResult:
    """
    å¤„ç† chat æµå¼å“åº”ï¼ŒåŒæ—¶æµå¼å‘é€æ–‡æœ¬ç»™å®¢æˆ·ç«¯ã€‚
    
    æ­¤å‡½æ•°ä¼šç«‹å³å°†æ–‡æœ¬ delta å‘é€ç»™å®¢æˆ·ç«¯ï¼Œ
    å®ç°çœŸæ­£çš„æµå¼å“åº”ï¼Œé™ä½é¦–å­—å»¶è¿Ÿã€‚
    
    è¿”å› ChatStreamResultï¼ŒåŒ…å«å®Œæ•´æ–‡æœ¬å†…å®¹æˆ–å·¥å…·è°ƒç”¨ä¿¡æ¯ã€‚
    
    äº‹ä»¶æ—¶åºï¼ˆä¸ OpenAI å®˜æ–¹å¯¹é½ï¼‰ï¼š
    
    æ–‡æœ¬å“åº”ï¼š
    1. ResponseCreatedEvent
    2. ResponseOutputItemAddedEvent
    3. ConversationItemAdded
    4. ResponseContentPartAddedEvent
    5. ResponseOutputTextDeltaEvent (å¤šä¸ª)
    6. ResponseOutputTextDoneEvent
    7. ResponseContentPartDoneEvent
    8. ResponseOutputItemDoneEvent
    9. ConversationItemDone
    10. ResponseDoneEvent
    
    å·¥å…·è°ƒç”¨ï¼š
    1. ResponseCreatedEvent
    2. ResponseOutputItemAddedEvent  
    3. ConversationItemAdded
    4. ResponseFunctionCallArgumentsDeltaEvent (å¤šä¸ª)
    5. ResponseFunctionCallArgumentsDoneEvent
    6. ConversationItemDone
    7. ResponseOutputItemDoneEvent
    8. ResponseDoneEvent
    """
    result = ChatStreamResult()
    text_ctx: Optional[TextResponseContext] = None
    func_ctx: Optional[FunctionCallResponseContext] = None
    mcp_ctx: Optional[McpCallResponseContext] = None
    
    # ç”¨äºç´¯ç§¯å·¥å…·è°ƒç”¨å‚æ•°
    tool_name: Optional[str] = None
    tool_call_id: Optional[str] = None
    is_mcp_tool: bool = False
    mcp_server_label: Optional[str] = None
    
    try:
        async for chunk in chat_stream:
            # ğŸ”´ æ£€æŸ¥æ˜¯å¦éœ€è¦å–æ¶ˆï¼ˆæ–°è½¬å†™äº‹ä»¶åˆ°æ¥ï¼‰
            if session.is_cancel_requested():
                logger.info("Chat stream cancelled due to new transcription")
                result.was_cancelled = True
                break
            
            delta = chunk.choices[0].delta
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            if delta.tool_calls:
                tool_call = delta.tool_calls[0]
                function = tool_call.function
                
                # é¦–æ¬¡å‡ºç°å·¥å…·è°ƒç”¨åç§°ï¼Œåˆ¤æ–­æ˜¯å¦ä¸º MCP å·¥å…·å¹¶åˆ›å»ºå¯¹åº”ä¸Šä¸‹æ–‡
                if function.name:
                    tool_name = function.name
                    tool_call_id = tool_call.id
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸º MCP å·¥å…·
                    is_mcp_tool = session.is_mcp_tool(tool_name)
                    
                    if is_mcp_tool:
                        mcp_server_label = session.get_mcp_server_for_tool(tool_name)
                        mcp_ctx = McpCallResponseContext(
                            session=session,
                            name=tool_name,
                            server_label=mcp_server_label,
                        )
                        await mcp_ctx.__aenter__()
                        if function.arguments:
                            await mcp_ctx.send_arguments_delta(function.arguments)
                    else:
                        # æ™®é€š function call
                        func_ctx = FunctionCallResponseContext(
                            session=session,
                            name=tool_name,
                            call_id=tool_call_id,
                        )
                        await func_ctx.__aenter__()
                        if function.arguments:
                            await func_ctx.send_arguments_delta(function.arguments)
                elif function.arguments:
                    # åç»­å‚æ•°å¢é‡
                    if mcp_ctx:
                        await mcp_ctx.send_arguments_delta(function.arguments)
                    elif func_ctx:
                        await func_ctx.send_arguments_delta(function.arguments)
            
            # ğŸš€ æµå¼å‘é€æ–‡æœ¬å†…å®¹
            if delta.content:
                # å»¶è¿Ÿåˆ›å»ºä¸Šä¸‹æ–‡ï¼Œåœ¨ç¬¬ä¸€ä¸ªæ–‡æœ¬åˆ°è¾¾æ—¶æ‰å‘é€å‰ç½®äº‹ä»¶
                if text_ctx is None:
                    text_ctx = TextResponseContext(session)
                    await text_ctx.__aenter__()
                
                result.content += delta.content
                await text_ctx.send_text_delta(delta.content)
        
        # æµç»“æŸåï¼Œå¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œè®°å½•ç»“æœ
        if mcp_ctx and tool_call_id:
            # MCP å·¥å…·è°ƒç”¨ - å®Œæˆå‚æ•°å‘é€é˜¶æ®µ
            await mcp_ctx.finish_arguments()
            
            result.tool_call = ToolCallInfo(
                call_id=tool_call_id,
                name=tool_name or "",
                arguments=mcp_ctx.arguments,
                is_mcp=True,
                server_label=mcp_server_label,
                mcp_ctx=mcp_ctx,  # ä¼ é€’ä¸Šä¸‹æ–‡ç»™ servicer
            )
            logger.info(
                f"MCP tool call detected: name={tool_name}, "
                f"server_label={mcp_server_label}, arguments={mcp_ctx.arguments}"
            )
            # æ³¨æ„ï¼šmcp_ctx ä¸åœ¨è¿™é‡Œå…³é—­ï¼Œç”± servicer åœ¨æ‰§è¡Œè°ƒç”¨åå…³é—­
        elif func_ctx and tool_call_id:
            # æ™®é€š function call
            result.tool_call = ToolCallInfo(
                call_id=tool_call_id,
                name=tool_name or "",
                arguments=func_ctx.arguments,
                is_mcp=False,
            )
            logger.info(
                f"Function call detected: name={tool_name}, call_id={tool_call_id}, "
                f"arguments={func_ctx.arguments}"
            )
        elif result.content:
            logger.info(f"Chat stream response sent: content='{result.content}'")
    
    except asyncio.CancelledError:
        # ä»»åŠ¡è¢«çœŸæ­£å–æ¶ˆï¼ˆTask.cancel()ï¼‰
        logger.info("Chat stream task was cancelled by CancelledError")
        result.was_cancelled = True
        # æ˜¾å¼å…³é—­ç”Ÿæˆå™¨ï¼Œåœæ­¢åº•å±‚ HTTP æµ
        if hasattr(chat_stream, 'aclose'):
            try:
                await chat_stream.aclose()
            except Exception as e:
                logger.debug(f"Error closing chat stream: {e}")
        raise  # é‡æ–°æŠ›å‡ºè®©è°ƒç”¨è€…çŸ¥é“ä»»åŠ¡è¢«å–æ¶ˆ
    
    finally:
        # ç¡®ä¿ä¸Šä¸‹æ–‡æ­£ç¡®å…³é—­ï¼Œå‘é€åç½®äº‹ä»¶
        if text_ctx is not None:
            await text_ctx.finish(cancelled=result.was_cancelled)
        if func_ctx is not None:
            await func_ctx.__aexit__(None, None, None)
        # æ³¨æ„ï¼šMCP ä¸Šä¸‹æ–‡éœ€è¦åœ¨æ‰§è¡Œè°ƒç”¨åå…³é—­ï¼Œè¿™é‡Œä¸å…³é—­
        
        # ğŸ”´ å¦‚æœè¢«å–æ¶ˆï¼Œæ‰‹åŠ¨å°†éƒ¨åˆ†å†…å®¹æ·»åŠ åˆ°å†å²è®°å½•
        # æ­£å¸¸ç»“æŸæ—¶ï¼Œchat_session.get_result_record_itr ä¼šè‡ªåŠ¨å¤„ç†
        # ä½†è¢«å–æ¶ˆæ—¶æµä¸ä¼šæ­£å¸¸ç»“æŸï¼Œéœ€è¦æ‰‹åŠ¨æ·»åŠ 
        if result.was_cancelled and result.content:
            from openai.types.chat import ChatCompletionMessage
            cancelled_message = ChatCompletionMessage(
                role="assistant",
                content=result.content,  # ä¿å­˜å·²ç”Ÿæˆçš„éƒ¨åˆ†å†…å®¹
                tool_calls=[],
            )
            session.chat_session.chat_history.append(cancelled_message)
            logger.info(
                f"Cancelled chat partial content saved to history: '{result.content}'"
            )
    
    return result


async def send_tool_result_response(
    session: "RealtimeSession",
    chat_stream: Iterable[ChatCompletionChunk],
):
    """
    å‘é€å·¥å…·è°ƒç”¨ç»“æœåçš„å“åº”æµã€‚
    ä½¿ç”¨ TextResponseContext å‘é€å®Œæ•´çš„äº‹ä»¶åºåˆ—ï¼ˆåŒ…æ‹¬ response.created ç­‰å‰ç½®äº‹ä»¶ï¼‰ã€‚
    """
    async with TextResponseContext(session) as ctx:
        async for chunk in chat_stream:
            delta = chunk.choices[0].delta
            if delta and delta.content:
                await ctx.send_text_delta(delta.content)
    
    logger.info(f"Tool result response sent: content='{ctx.content}'")


async def send_text_response(session: "RealtimeSession", content: str):
    """å‘é€çº¯æ–‡æœ¬å“åº”ï¼ˆä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼‰"""
    async with TextResponseContext(session) as ctx:
        await ctx.send_text_delta(content)


async def send_chat_stream_response(
    session: "RealtimeSession",
    response_chunk: Iterable[str],
):
    """å‘é€æµå¼èŠå¤©å“åº”ï¼ˆä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼‰"""
    async with TextResponseContext(session) as ctx:
        async for chunk in response_chunk:
            await ctx.send_text_delta(chunk)
